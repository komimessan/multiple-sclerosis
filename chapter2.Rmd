
# Temporal features extraction

As previously done in [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf), several features can be extracted from drawing shape by an MS patient to capture temporal, spatial,and spatiotemporal factors in the drawing task that could be an indicative of manual dexterity. Thus we start by calculating each of these features:

## Velocity, radial and angular velocity

To measure temporal irregularities, several authors ( [Banaszkiewicz et al., 2008](https://europepmc.org/article/med/19353440), [Memedi et al., 2015](https://www.mdpi.com/1424-8220/15/9/23727), [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf) ) calculated the drawing velocities,angular and radial velocities to illustrate temporal features that may emerge in the upper extremity function of MS patients. These features were calculated using the following formula from ( [Memedi et al., 2015](https://www.mdpi.com/1424-8220/15/9/23727) and [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf) ):


$$v = \sum_{i=1}^{N-1} \frac{\sqrt{(x_{i+1}-x_i)^2 + (y_{i+1}-y_i)^2}}{t_{i+1}-t_i}$$
with $v$ the drawing velocity. Radial velocity (RV) is calculated as:
$$RV = \sum_{i=1}^{N-1} \frac{r_{i+1}-r_i}{t_{i+1}-t_i}$$
where $r = \sqrt{x^2+y^2}$ is the radius. Angular velocity (RHOV) is also calculated as 

$$RHOV = \sum_{i=1}^{N-1} \frac{\theta_{i+1}-\theta_i}{t_{i+1}-t_i}$$

where $\theta = tan^{-1}\left(\frac{y}{x}\right)$. $x$ and $y$ in each formula are the coordinates of the drawing pixel and $t$ is time in seconds. $N$ is the total number of pixel.




```{r  message=FALSE, warning=FALSE, include=FALSE}

## Read scaled data
ms_data.xy_sc <- read.csv("data_xy_scale.csv", header = TRUE)

## Calculate velocity (v), radial velocity (rv), angular velocity (av) by patients, test date, and difficulty level
## Initialize velocity (v), radial velocity (rv), angular velocity (rhov)

veclocity_func <- function(data, xs, ys){
  ## data is the entire dataset with x and y scaled
  ## xs is the x coordinates to use (either x_scf or x_scc)
  ## ys is the y coordinates to use (either y_scf or y_scc)
  
  data[,"d_t"] <- 0 ## intialize an empty 0 column of delta time
  data[,"v_i"] <- 0 ## intialize an empty 0 column of velocities
  data[,"rv_i"] <- 0 ## intialize an empty 0 column of radial velocities
  data[,"av_i"] <- 0 ## intialize an empty 0 column of angular velocities
  
  # create an empty dataframe to be used later
  new.tr.level <- data[0,]
  
  ## factor levels of patient ID
  p.id <- levels(factor(data$patient_id))
  
  for (id in p.id) {
    patient_data <- subset(data, patient_id==id) ## select a single patient
    n.test <- levels(factor(patient_data$ntest_date))
    for (tn in n.test) {
      test_date <- subset(patient_data, ntest_date==tn) ## select one test date
      d.levels <- levels(factor(test_date$difficulty_level))
      for (dl in d.levels) {
        d.level <- subset(test_date, difficulty_level==dl) ## select difficulty level
        tr.levels <- levels(factor(d.level$trial_id))
        for (tr in tr.levels){
          tr.level <- subset(d.level, trial_id==tr) ## select trial_id
          dim_tr.level1 <- dim(tr.level)[1] ## Make sure the dimension of each trial > 2
          if (dim_tr.level1>2){
            for (i in 1:(dim_tr.level1 - 1)) {
              tr.level[i+1,"d_t"] <- (tr.level$time[i+1]-tr.level$time[i]) # delta time
              tr.level[i+1,"v_i"] <- sqrt((tr.level[i+1,xs] - tr.level[i,xs])^2 +
                                            (tr.level[i+1,ys] - tr.level[i,ys])^2
              )/(tr.level$time[i+1]-tr.level$time[i]) # velocity
              tr.level[i+1,"rv_i"] <- (sqrt((tr.level[i+1,xs])^2 + (tr.level[i+1,ys])^2) -                                       sqrt((tr.level[i,xs])^2 + (tr.level[i,ys])^2)
              )/(tr.level$time[i+1]-tr.level$time[i]) # radial velocity
              tr.level[i+1,"av_i"] <- (atan(tr.level[i+1,ys]/tr.level[i+1,xs]) -
                                         atan(tr.level[i,ys]/tr.level[i,xs])
              )/(tr.level$time[i+1]-tr.level$time[i]) # angular velocity
              
            }
            new.tr.level <- rbind(new.tr.level, tr.level) ## append the data
          }
        }
      }
    }
  }
  
  return(as.data.frame(new.tr.level))  
}

# #### Calculate the velocity
# ptm <- proc.time() ## Check how long it will run (takes 7.6 min to run)
# 
# ms_data4 <- veclocity_func(ms_data.xy_sc,"x" ,"y")
# 
# proc.time() - ptm
# # 
# # write.csv(ms_data4, file = "new_spiral.csv")
# 
# ## The code to calculate v, rv, and av take long so the data was saved to be used later
ms_data4 <- read.csv("new_spiral.csv", header = TRUE)

```





```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width= 16}

## Create a function that will use Fourier Transform to lowpass filter the data
filter_func <- function(x, t, fc){
  ## x is the vector array that need to be filter
  ## t the time component of the vector array
  ## cf is the cut off frequency
  
  ## fs (sampling frequency)= no of samples/ sampling time (max time)
  fs <- length(x)/max(t)   # sampling frequency
  ns <- length(x)  # number of samples
  ## convert sample to ts object with sampling rate as fs
  s <- na.omit(ts(x, frequency = fs)) 
  ft <- fft(s) ## fourier transform
  lft <- length(ft) ## length of fourier transform
  bin <- ns/(fs/fc) ## Create the upper bin cut-off point
  
  if (lft>=bin){
    ft[-c(1:bin, (lft-bin):lft)] <- 0 ## Null the upper bins
  } else{
    ft <- ft ## No filter if lft is larger than bin
  }
  x_lowpass.f <- Re(fft(ft, inv=TRUE))/lft ## lowe pass filter
  return(x_lowpass.f)
}



#### Function to create plotting data point acconrding to true spiral appendage

spiral_data_func <- function(data, patientID, ntest){
  ## data is the dataframe
  ## patientID is the patient Id
  ## ntest is the nth number of testdate for patient i
  
  p1 <- subset(data, patient_id == patientID)
  p1$difficulty_level <- factor(p1$difficulty_level, 
                                labels = c("Difficulty Level 1","Difficulty Level 2",
                                           "Difficulty Level 3"))
  p11 <- subset(p1, ntest_date==ntest) ## select one test date (1)
  p11_sub <- p11 %>% 
    group_by(difficulty_level) %>% 
    dplyr::filter(trial_id==levels(factor(trial_id))[1]) %>% 
    dplyr::select(patient_id, testdate, difficulty_level, trial_id, ntest_date,time, 
                  x, y, x_scf, y_scf, x_scc, y_scc, v_i, rv_i, av_i, appendage)
  
  ## generate spiral with difficulty 1, 2, and 3
  dl1 <- "Difficulty Level 1"
  dl2 <- "Difficulty Level 2"
  dl3 <- "Difficulty Level 3"
  append1 <- subset(p11_sub,difficulty_level == dl1)$appendage[1]
  append2 <- subset(p11_sub,difficulty_level == dl2)$appendage[1]
  append3 <- subset(p11_sub,difficulty_level == dl3)$appendage[1]
  
  spiral_dl1 <- as.data.frame(GenerateSpiral(append1,1))
  spiral_dl1$difficulty_level = rep(dl1, dim(spiral_dl1)[1])
  spiral_dl2 <- as.data.frame(GenerateSpiral(append2,2))
  spiral_dl2$difficulty_level = rep(dl2, dim(spiral_dl2)[1])
  spiral_dl3 <- as.data.frame(GenerateSpiral(append3,3))
  spiral_dl3$difficulty_level = rep(dl3, dim(spiral_dl3)[1])
  
  spiral_data <- rbind(spiral_dl1, spiral_dl2, spiral_dl3)
  colnames(spiral_data) <- c("xt","yt","linewidth","difficulty_level")
  
  return(list(patient_spiral = p11_sub, true_spiral = spiral_data))
  #spiral_dat <- merge(p11_sub,spiral_LH, by = "difficulty_level", all = TRUE)
}

```




```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width= 16}
## Compute the spiral according to the appendage and extract data for plotting
spiral_data <- spiral_data_func(ms_data4, "NDS691","1")
patient_spiral <- as.data.frame(spiral_data$patient_spiral)
true_spiral <- as.data.frame(spiral_data$true_spiral)
linewidth <- spiral_data$true_spiral$linewidth

##### Spiral plots
## raw drawing
##  lwd=1 is equal to 1/96 inch, which is exactly as 0.75 * 1/72 inch (0.75pt)
ggplot()+
  geom_path(data = true_spiral, aes(x=xt, y= yt), lwd = (linewidth*96)/3, color = "orange") +
  geom_point(data = patient_spiral, aes(x=x, y= y), size  = 2)+ ## cohort spiral
  geom_path(data = patient_spiral, aes(x=x, y= y), size = .9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "X-Coordinates", y = "Y-Coordinates") + 
  theme_bw() + Nice.Label

## spiral normalized drawing using first entry rule
ggplot()+
  geom_path(data = true_spiral, aes(x=xt, y= yt), lwd = (linewidth*96)/3, color = "orange") +
  geom_point(data = patient_spiral, aes(x=x_scf, y= y_scf), size  = 2)+ ## cohort spiral
  geom_path(data = patient_spiral, aes(x=x_scf, y= y_scf), size = .9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "X-Coordinates", y = "Y-Coordinates") + 
  theme_bw() + Nice.Label

## spiral normalized drawing using center rule
ggplot()+
  geom_path(data = true_spiral, aes(x=xt, y= yt), lwd = (linewidth*96)/3, color = "orange") +
  geom_point(data = patient_spiral, aes(x=x_scc, y= y_scc), size  = 2)+ ## cohort spiral
  geom_path(data = patient_spiral, aes(x=x_scc, y= y_scc), size = .9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "X-Coordinates", y = "Y-Coordinates") + 
  theme_bw() + Nice.Label

####### velocity vs. time plot
ggplot(patient_spiral, aes(x=time, y= filter_func(v_i,time,8)))+
  geom_point(size  = 2.0)+
  geom_line(size = 0.9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "Time (s)", y = "Drawing Velocity (Pixels/s)") + 
  theme_bw()+Nice.Label 

```



## Power Spectral Density and dominant frequency


```{r  message=FALSE, warning=FALSE, include=FALSE}
## calculate the sum, coefiicient of variation, skew for v, rv, and av
## Function to calculate coefficient of variation
cv = function(vector){
  coefvar <- sd(vector, na.rm = TRUE)/ mean(vector, na.rm = TRUE)
  return(coefvar)
}

ms_data.sum <- ms_data4 %>% 
  group_by(patient_id,ntest_date,difficulty_level, trial_id) %>% 
  summarise(v_sum = sum(v_i, na.rm = TRUE), v_cv = cv(v_i), 
            v_sk = skewness(v_i, na.rm = TRUE), v_kt = kurtosis(v_i, na.rm = TRUE), 
            rv_sum = sum(rv_i, na.rm = TRUE), rv_cv = cv(rv_i), 
            rv_sk = skewness(rv_i, na.rm = TRUE), rv_kt = kurtosis(rv_i, na.rm = TRUE),
            av_sum = sum(av_i,na.rm = TRUE), av_cv = cv(av_i), 
            av_sk = skewness(av_i, na.rm = TRUE), av_kt = kurtosis(av_i, na.rm = TRUE))


#### Power Spectral Density using Welsh periodogram with a Hamming window
## Maximum PSD and dominant i.e., frequency corresponding to max(PSD)--see Creagh et. al, 2020

## function to calculate PSD with hamming window of length = length(velocity vector)
pwelch_func <- function(vector){
  result = pwelch(vector, window = hamming(length(vector)), plot = FALSE)
  freq = result$freq
  spec = result$spec
  return(as.data.frame(list(freq=freq,spec=spec)))
}
  
  
ms_data.psd <- ms_data4 %>% 
   group_by(patient_id, ntest_date, difficulty_level, trial_id) %>%
  summarise(v_psd.max = max(pwelch_func(filter_func(v_i,time,7))$spec), 
            v_df = pwelch_func(filter_func(v_i,time,7))$freq[which.max(pwelch_func(filter_func(v_i,time,7))$spec)],
            rv_psd.max = max(pwelch_func(filter_func(rv_i,time,7))$spec),
            rv_df = pwelch_func(filter_func(rv_i,time,7))$freq[which.max(pwelch_func(filter_func(rv_i,time,7))$spec)],
            av_psd.max = max(pwelch_func(filter_func(av_i,time,7))$spec),
            av_df = pwelch_func(filter_func(av_i,time,7))$freq[which.max(pwelch_func(filter_func(av_i,time,7))$spec)])

### Power vs. frequency plot
## Create the data frame by filtering and calculating the power

# p11_sub1 <- subset(p11_sub, difficulty_level == "Difficulty Level 1")
# p11_sub2 <- subset(p11_sub, difficulty_level == "Difficulty Level 2")
# p11_sub3 <- subset(p11_sub, difficulty_level == "Difficulty Level 3")
# 
# psd_df1 <- data.frame(difficulty_level = "Difficulty Level 1",
#                       pwelch_func(filter_func(p11_sub1$v_i, p11_sub1$time, 8)))
# psd_df2 <- data.frame(difficulty_level = "Difficulty Level 2",
#                       pwelch_func(filter_func(p11_sub2$v_i, p11_sub2$time, 8)))
# psd_df3 <- data.frame(difficulty_level = "Difficulty Level 3",
#                       pwelch_func(filter_func(p11_sub3$v_i, p11_sub3$time, 8)))
# 
# psd_df <- rbind(psd_df1,psd_df2,psd_df3) ## row bind psd for all difficulty levels
# 
# ggplot(psd_df, aes(x =freq,spec))+
#   geom_point(size  = 2.0)+
#   geom_line(size = 0.9) +
#   facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
#   labs(x = "Frequency (Hz)", y = expression("Power (Pixels/s) "^2)) + 
#   theme_bw()+Nice.Label 


```



```{r  message=FALSE, warning=FALSE, include=FALSE}

### "NIB657"    "NIB659"    "NIB661"    "NIB662"    "NIB663"    "NIB664"    "PATIENT10" 
##"NDS688"    "NDS689"    "NDS690"    "NDS691"    "NDS692"    "NDS693"    "NDS694"    "NDS696"
p1 <- subset(ms_data4, patient_id=="NDS667") ## select single patient ## NIB112 ##NDS668
p11 <- subset(p1, ntest_date=="1") ## select one test date (1)
p111 <- subset(p11, difficulty_level=="1") ## select single difficulty level (1)
p1111 <- subset(p111, trial_id == "1A04mNtHZL8byD7ESgy6") #p111$trial_id[1]) ## "JSpymPxwdnXwvLzXpjym"
##

x<- p1111$x - p1111$x[25]
y<- p1111$y - p1111$y[25]

t <- p1111$time
x <- p1111$av_i
z <- filter_func(x, t, 8) # apply filter
## fs (sampling frequency)= no of samples/ sampling time (max time)
## The highest frequency  is assumed to be fs/2

pz <- pwelch_func(z) 

plot(pz$freq,pz$spec, 'o')

plot(t,x,'o')
lines(t,z,col="orange")

```




```{r  echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width= 10}

library(VennDiagram)

spiraldata1 <- read.csv("spiralDS1.csv", header = TRUE)

Spiral_Vanessa <- ms_data$patientID
Spiral_Peter <- spiraldata1$metaData.ID

S_vanessa.l <- length(levels(factor(Spiral_Vanessa)))
S_Peter.l <- length(levels(factor(Spiral_Peter)))
cross.area <- length(intersect(Spiral_Vanessa,Spiral_Peter))
diff_Van.Pet <- setdiff(Spiral_Vanessa,Spiral_Peter)
diff_Pet.Van <- setdiff(Spiral_Peter,Spiral_Vanessa)

grid.newpage();
venn.plot <- draw.pairwise.venn(area1 = S_vanessa.l, 
                                area2 = S_Peter.l, 
                                cross.area = cross.area,
                                #col = "red",
                                lty = "blank",
                                cat.cex = c(1.5,1.5), cex = c(2.5,2.5,2.5),
                 fill = c("green", "blue"),
                 category = c("Vanessa Data", "Peter Data"));
grid.draw(venn.plot)


### Splitting the dataset
#a # original data frame

#train<-sample_frac(a, 0.7)
#sid<-as.numeric(rownames(train)) # because rownames() returns character
#test<-a[-sid,]

## euclidean distance
euc.dist <- function(x2,y2){
  x1 <- 0
  y1 <- 0
  return(sqrt((x1 - x2) ^ 2 + (y1-y2)^2))
}

ms_dist <- tibble::as_tibble(ms_data4) %>% 
  group_by(patient_id, ntest_date, difficulty_level, trial_id) %>% 
  summarise(dist = euc.dist(x,y)) %>% 
  slice(1)

ms_dist$difficulty_level <- factor(ms_dist$difficulty_level, 
                                   labels = c("Difficulty Level 1",
                                              "Difficulty Level 2",
                                              "Difficulty Level 3") )


ggplot(ms_dist, aes(x=dist)) +
  geom_histogram(color="darkblue", fill="lightblue", bins = 50) +
  facet_wrap(~difficulty_level, nrow = 1, scales = "free") +
  labs(x = "Euclidean Distance between (0,0) and First Spiral Point", y = "Count") +
  theme_bw() + Nice.Label

ms_dist.var <- tibble::as_tibble(ms_dist)  %>% 
  group_by(patient_id, difficulty_level) %>% 
  summarise(dist_var = var(dist))

ggplot(ms_dist.var, aes(x=dist_var)) +
  geom_histogram(color="darkblue", fill="lightblue", bins = 10) +
  facet_wrap(~difficulty_level, nrow = 1, scales = "free") +
  labs(x = "Variance of Euclidean Distance by Patient", y = "Count") +
  theme_bw() + Nice.Label
####

## https://slowkow.com/notes/ggplot2-color-by-density/
get_density <- function(x, y, ...) {
  dens <- MASS::kde2d(x, y, ...)
  ix <- findInterval(x, dens$x)
  iy <- findInterval(y, dens$y)
  ii <- cbind(ix, iy)
  return(dens$z[ii])
}


x_dat <- cut(p1111$x,50)
y_dat <- cut(p1111$y,50)
time <- p1111$time
dat <- data.frame(x=x_dat,y=y_dat,time=time)

dat <- expand.grid(x = x_dat, y= y_dat)
dat <- matrix(dat, ncol = 50)

dat <- data.frame(x = p1111$x, y = p1111$y, time)




ggplot(dat, aes(x,y)) +
  geom_raster(aes(fill = after_stat(time)),interpolate = TRUE, hjust = 0, vjust = 0) +
  scale_fill_distiller("Time [s]", palette = "RdYlBu", direction = -1) +
  #viridis::scale_fill_viridis("Time [s]", discrete = FALSE) +
  theme_bw(base_size = 18) +
   theme(axis.title.x=element_blank(), axis.text.x=element_blank(), 
         axis.ticks.x=element_blank(),axis.title.y=element_blank(), 
         axis.text.y=element_blank(), axis.ticks.y=element_blank(), 
         panel.background = element_rect(fill = "blue",
                                colour = "blue", 
                                size = 0.5, linetype = "solid"),
         panel.grid.major = element_line(size = 0.5, linetype = 'solid',
                                colour = "black"),
         legend.key.height = unit(2.1, "cm")) 
  

p <- ggplot(dat, aes(x, y, fill = time)) +
  stat_bin_2d(bins = 50, drop = FALSE) +
  scale_fill_distiller("Time [s]", palette = "RdYlBu", direction = -1) +
  theme_bw(base_size = 18) +
   theme(axis.title.x=element_blank(), axis.text.x=element_blank(), 
         axis.ticks.x=element_blank(),axis.title.y=element_blank(), 
         axis.text.y=element_blank(), axis.ticks.y=element_blank(), 
         panel.grid.major = element_line(size = 0.5, linetype = 'solid',
                                colour = "black"),
         legend.key.height = unit(2.1, "cm")) 

ggplot_build(p)$data[[1]]$count

```

