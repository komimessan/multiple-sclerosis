# Introduction

Smartphone devices may be an easier alternative to obtain data from patients outside of clinics and hospitals environment. In this project, smartphone-based data were obtained from Multiple Sclerosis (MS) patients using a drawing a spiral test. The test was administered in order to measure upper extremity functionality. 

```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
### Libraries
library(openxlsx) ## v. 4.1.5
library(dplyr) ## v. 1.0.0
library(ggplot2) ## v. 3.3.1
library(wavelets) ## v. 0.3.0.2 ## for wavelet transform -- https://cran.r-project.org/web/packages/wavelets/wavelets.pdf
library(signal) ## v. 0.7.6 ## for filtering -- https://cran.r-project.org/web/packages/signal/signal.pdf
library(e1071) ## v. 1.7.3
library(psd) ## v. 2.1.0 ## power spectral density -- https://cran.r-project.org/web/packages/psd/psd.pdf
library(TSEntropies) ## v. 0.9 ## to calculate Approximate Entropies (ApEn)-- https://cran.r-project.org/web/packages/TSEntropies/TSEntropies.pdf
library(oce) ## v.1.2.0 ## oceanographic library which contain PSD with hamming window
library(tidyr) ## v. 1.1.0 ## for gather and wide
```




```{r  message=FALSE, warning=FALSE, include=FALSE}
### Import data
## Description of the data is as follow
# metaData.ID = Subject ID
# x: distance (in inches) of the spot drawn from the center of the screen
# y: distance (in inches) of the spot drawn from the center of the screen
# p: estimated pressure of the tap (based off of surface area)
# t: UNIX timestamp of when the drawing happened (to the millisecond)
# sumData.Num turns: the number of turns in the spiral 
# sumData.Line width: the width of the lines of the spiral
# time.point: UNIX timestamp of the drawing (this time in seconds)
# metaData.ID: Subject/patient specific ID


ms_data <- read.csv("spiralDataCorrected.csv", header = TRUE)
metadata <- read.xlsx("Handedness.xlsx", colNames = TRUE)

## add a test date to the data 
ms_data$testdate <- substr(ms_data$testDate,1,10)

## Remove non-relevant rows that have patient ID such as x:1234455
ms_data <- ms_data[substr(ms_data$patientID,1,2) != "x:" & 
                     substr(ms_data$patientID,1,2) != "{t" & 
                     substr(ms_data$patientID,1,2) != "y:" &
                     substr(ms_data$patientID,1,2) != "z:" &
                     substr(ms_data$patientID,1,2) != "t:" &
                     substr(ms_data$patientID,1,2) != "" &
                     substr(ms_data$patientID,1,11) != "UPLOAD_DATE" &
                     substr(ms_data$patientID,1,9) != "Altitude:",]

## and convert variable to numeric
ms_data$x <- as.numeric(as.character(ms_data$x))
ms_data$y <- as.numeric(as.character(ms_data$y))
ms_data$t <- as.numeric(as.character(ms_data$t))
ms_data$p <- as.numeric(as.character(ms_data$p))
ms_data$age <- as.numeric(as.character(ms_data$age))


## add visit number based on patientID and difficulty level, remove some columns and change column names
ms_data2 <- ms_data %>% 
  group_by(patientID, difficulty) %>%
  mutate(ntest_date = factor(testdate, labels = 1:length(unique(testdate)))) %>% 
  dplyr::select(trialID, patientID,x,y,t,p,ntest_date,difficulty,age, testdate, appendage) %>% 
  dplyr::rename(trial_id = trialID, patient_id=patientID,difficulty_level=difficulty)

  
ms_data2$t <- ms_data2$t/1000 ## convert time point from milliseconds to seconds 

## add time that is scaled from 0 by patient_id, ntest_date, and difficulty_level and remove duplicate x, y, t
ms_data2 <- ms_data2 %>% 
  group_by(patient_id, ntest_date, difficulty_level, trial_id) %>% 
  distinct(x,y,t,p, .keep_all = TRUE) %>% 
  arrange(t) %>% 
  mutate(pixel = row_number(), time = t-t[1])

## Select Patient_id from the main data that are in the Patient code of the metadata
ms_data2 <- ms_data2 %>% dplyr::filter(patient_id %in% metadata$PatientCode)


#### Add new diagnosis category to the metadata (MS, HV, and Others for all others disorder)
metadata$diagnosis_group <- ifelse(metadata$Diagnosis=="MS","MS",
                                   ifelse(metadata$Diagnosis=="HV","HV", "Others"))

## Convert birth dates to date format
metadata$`Birth.month/year` <- as.Date(metadata$`Birth.month/year`, origin = "1900-01-01")

## Create metadata that contain patient that intersect with those in the ms_data
metadata_sub <- metadata %>% 
  dplyr::filter(PatientCode %in% ms_data2$patient_id) %>% 
  dplyr::rename(dominant_hand = Dominant.Hand, patient_id=PatientCode,
                birth_date=`Birth.month/year`, gender=Gender, diagnosis=Diagnosis)

### Join the metadata to the ms_data2 
ms_data3 <- merge(ms_data2,metadata_sub, by = "patient_id")


## Recalculate the age from their birth date to the testdate
ms_data3$age <- round(lubridate::time_length(difftime(ms_data3$testdate,
                                                ms_data3$birth_date),"years"))
## Arrange ms_data3 by patient_id,ntest_date, difficulty_level, trial_id, and time

ms_data3 <- arrange(ms_data3,patient_id,ntest_date, difficulty_level, trial_id, time)
  
```




```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width= 16}
# create template for plot labelling
black.bold.text1 <- element_text(face = "bold", color = "black",size=24) # x and y axis
black.bold.text2 <- element_text(face = "bold", color = "black",size=24) # title
Nice.Label <-theme(axis.text.x = element_text(face="bold", color="black", size=16),
         axis.text.y = element_text(face="bold", color="black", size=16),
         title=black.bold.text2,axis.title = black.bold.text1, legend.position = "right",legend.box = "vertical",
         legend.text = element_text(size=24),strip.text.x = element_text(face="bold",size=24)) #18 or 24

### Tranform from long tabel to wide table

metadata_sub.long <- metadata_sub %>% 
  dplyr::select(patient_id,diagnosis_group,dominant_hand, gender) %>% 
  tidyr::gather(group, attribute, diagnosis_group:gender, factor_key = TRUE) 

metadata_sub.long$group <- factor(metadata_sub.long$group,
                                  levels = c("diagnosis_group","gender","dominant_hand"),
                                  labels = c("Diagnosis Categories", "Gender", "Dominant Hand"))

### Plot the distribution of the type of data we have 
ggplot(metadata_sub.long, aes(x=attribute)) +
  geom_bar(colour = "gray", width = 0.5) +
  facet_wrap(~group, scales = "free", nrow = 1) +
  labs(x = " ", y = "Number of Cohorts") +
  theme_bw()+Nice.Label

```



# Features extraction

As previously done in [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf), several features can extracted from drawing shape by an MS patient to capture temporal, spatial,and spatiotemporal factors in the drawing task that could be an indicative of manual dexterity. Thus we start by calculating each of these features:

## Temporal features

To measure temporal irregularities, several authors ( [Banaszkiewicz et al., 2008](https://europepmc.org/article/med/19353440), [Memedi et al., 2015](https://www.mdpi.com/1424-8220/15/9/23727), [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf) ) calculated the drawing velocities,angular and radial velocities to illustrate temporal features that may emerge in the upper extremity function of MS patients. These features were calculated using the following formula from ( [Memedi et al., 2015](https://www.mdpi.com/1424-8220/15/9/23727) and [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf) ):


$$v = \sum_{i=1}^{N-1} \frac{\sqrt{(x_{i+1}-x_i)^2 + (y_{i+1}-y_i)^2}}{t_{i+1}-t_i}$$
with $v$ the drawing velocity. Radial velocity (RV) is calculated as:
$$RV = \sum_{i=1}^{N-1} \frac{r_{i+1}-r_i}{t_{i+1}-t_i}$$
where $r = \sqrt{x^2+y^2}$ is the radius. Angular velocity (RHOV) is also calculated as 

$$RHOV = \sum_{i=1}^{N-1} \frac{\theta_{i+1}-\theta_i}{t_{i+1}-t_i}$$

where $\theta = tan^{-1}\left(\frac{y}{x}\right)$. $x$ and $y$ in each formula are the coordinates of the drawing pixel and $t$ is time in seconds. $N$ is the total number of pixel.




```{r  message=FALSE, warning=FALSE, include=FALSE}

# ## Calculate velocity (v), radial velocity (rv), angular velocity (av) by patients, test date, and difficulty level
# ## Initialize velocity (v), radial velocity (rv), angular velocity (rhov)
# ms_data3[,"d_t"] <- 0 ## intialize an empty 0 column of delta time
# ms_data3[,"v_i"] <- 0 ## intialize an empty 0 column of velocities
# ms_data3[,"rv_i"] <- 0 ## intialize an empty 0 column of radial velocities
# ms_data3[,"av_i"] <- 0 ## intialize an empty 0 column of angular velocities
# 
# # create an empty dataframe to be used later
# new.tr.level <- ms_data3[0,]
# 
# ## factor levels of patient ID
# p.id <- levels(factor(ms_data3$patient_id))
# 
# ptm <- proc.time() ## Check how long it will run (will take 53 min to run)
# 
# for (id in p.id) {
#   patient_data <- subset(ms_data3, patient_id==id) ## select a single patient
#   n.test <- levels(factor(patient_data$ntest_date))
#   for (tn in n.test) {
#     test_date <- subset(patient_data, ntest_date==tn) ## select one test date
#     d.levels <- levels(factor(test_date$difficulty_level))
#     for (dl in d.levels) {
#       d.level <- subset(test_date, difficulty_level==dl) ## select difficulty level
#       tr.levels <- levels(factor(d.level$trial_id))
#       for (tr in tr.levels){
#         tr.level <- subset(d.level, trial_id==tr) ## select trial_id
#         dim_tr.level1 <- dim(tr.level)[1] ## Make sure the dimension of each trial > 2
#         if (dim_tr.level1>2){
#           for (i in 1:(dim_tr.level1 - 1)) {
#             tr.level[i+1,"d_t"] <- (tr.level$time[i+1]-tr.level$time[i]) # delta time
#             tr.level[i+1,"v_i"] <- sqrt((tr.level$x[i+1] - tr.level$x[i])^2 +
#                                           (tr.level$y[i+1] - tr.level$y[i])^2
#             )/(tr.level$time[i+1]-tr.level$time[i]) # velocity
#             tr.level[i+1,"rv_i"] <- (sqrt((tr.level$x[i+1])^2 + (tr.level$y[i+1])^2) -                                       sqrt((tr.level$x[i])^2 + (tr.level$y[i])^2)
#             )/(tr.level$time[i+1]-tr.level$time[i]) # radial velocity
#             tr.level[i+1,"av_i"] <- (atan(tr.level$y[i+1]/tr.level$x[i+1]) -
#                                        atan(tr.level$y[i]/tr.level$x[i])
#             )/(tr.level$time[i+1]-tr.level$time[i]) # angular velocity
# 
#           }
#           new.tr.level <- rbind(new.tr.level, tr.level) ## append the data
#         }
#       }
#     }
#   }
# }
# proc.time() - ptm
# 
# # ## call the final data, ms_data4
# ms_data4 <- new.tr.level

## The code to calculate v, rv, and av take long so the data was saved to be used later
ms_data4 <- read.csv("new_spiralLH.csv", header = TRUE)


# ## Write the ms_data4 containing vi, rvi, and avi to the file to be used later
# #write.csv(ms_data4,file = "new_spiralLH.csv")
# 
# # #### Tryout for a single patient
# # 
# ms_data3p <- subset(ms_data3, v_i>0)

# ## 
# p1 <- subset(ms_data3, patient_id=="NIB112") ## select single patient ##NDS668, NDS670
# p11 <- subset(p1, ntest_date=="1") ## select one test date 
# p111 <- subset(p11, difficulty_level=="1") ## select single difficulty level 
# p1111 <- subset(p111, trial_id == p111$trial_id[1]) ## select one trial_id
#
# ### filter the speed fequency by 8 Hz
# bf <- butter(3, 0.08) # 8 Hz low-pass filter
# t <- p111$t - p111$t[1]
# x <- p111$v_i
# z <- filter(bf, x) # apply filter
# plot(t, x, type = "l")
# lines(t, z, col = "red")
#
# # #
# d.t = rep(0, dim(p1111)[1]) ## initialize delta time
# p1111_v = rep(0, dim(p1111)[1]) ## initialize the velocity of p111
# p1111_rv = rep(0, dim(p1111)[1]) ## initialize the radial velocity
# p1111_av = rep(0, dim(p1111)[1]) ## initialize the angular velocity
# #
# for (i in 1:(dim(p1111)[1]-1)){
#   d.t[i+1] = (p1111$time[i+1]-p1111$time[i])
#   p1111_v[i+1] <- sqrt((p1111$x[i+1] - p1111$x[i])^2 + (p1111$y[i+1] - p1111$y[i])^2)/(p1111$time[i+1]-p1111$time[i])
#   p1111_rv[i+1] <-  (sqrt((p1111$x[i+1])^2 + (p1111$y[i+1])^2) - sqrt((p1111$x[i])^2 + (p1111$y[i])^2))/(p1111$time[i+1]-p1111$time[i])
#   p1111_av[i+1] <-  (atan(p1111$y[i+1]/p1111$x[i+1]) - atan(p1111$y[i]/p1111$x[i]))/(p1111$time[i+1]-p1111$time[i])
# }
# # # 
# # p111_rv.dwt <- dwt(p111_rv, filter = "d10")
# # cp111_rv.dwt <- p111_rv.dwt@filter@h ## Coefficient
```





```{r  message=FALSE, warning=FALSE, include=FALSE}

#### Recreate the original spiral drawing from the App

## Turn Difficulty level into Number of Turns
DifficultyToNumberOfTurns <- function(difficulty){
  if(difficulty=="3"){
    return(5)
  } else if (difficulty == "2"){
    return(3)
  } else {
    return(2)
  }
}

## Turn difficulty level into the Line width
DifficultyToLineWidth <- function(difficulty){
  if(difficulty=="1"){
    return(6/32)
  } else if (difficulty == "2"){
    return(5/32)
  } else {
    return(4/32)
  }
}


## Function to generate the spiral data
GenerateSpiral = function(side, difficulty){
  ## side can either be LH or RH from the appendage in ms_data
  ## difficulty is the dificulty level from 1,2 or 3
  
  NumberOfTurns <- DifficultyToNumberOfTurns(difficulty)
  MaxAngleRadians <- 2*pi*NumberOfTurns
  MaxRadius <- 1.25
  AngleToRadiusScale <- MaxRadius/MaxAngleRadians
  AngleOffset <- pi/2
  InvertFactor <- ifelse(side=="LH",1,-1)
  
  CurAngleRadian <- 0
  x_vec <- vector() ## Initialize the x vector
  y_vec <- vector() ## initialize the y vector
  
  while (CurAngleRadian < MaxAngleRadians) {
    x <- CurAngleRadian*AngleToRadiusScale*cos((CurAngleRadian * InvertFactor) + AngleOffset)
    y <- CurAngleRadian*AngleToRadiusScale*sin((CurAngleRadian * InvertFactor) + AngleOffset)
    
    x_vec <- append(x_vec,x)
    y_vec <- append(y_vec,y)
    CurAngleRadian = CurAngleRadian + 0.1
  }
  
  linewidth <- rep(DifficultyToLineWidth(difficulty), length(x_vec))
  
  return(list(x=x_vec, y=y_vec, linewidth = linewidth))
}

## generate spiral with difficulty 1, 2, and 3
spiral_dl1.LH <- as.data.frame(GenerateSpiral("LH",1))
spiral_dl1.LH$difficulty_level = rep("Difficulty Level 1", dim(spiral_dl1.LH)[1])
spiral_dl2.LH <- as.data.frame(GenerateSpiral("LH",2))
spiral_dl2.LH$difficulty_level = rep("Difficulty Level 2", dim(spiral_dl2.LH)[1])
spiral_dl3.LH <- as.data.frame(GenerateSpiral("LH",3))
spiral_dl3.LH$difficulty_level = rep("Difficulty Level 3", dim(spiral_dl3.LH)[1])

spiral_LH <- rbind(spiral_dl1.LH, spiral_dl2.LH, spiral_dl3.LH)
```




```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width= 16}

## Create a function that will use Fourier Transform to lowpass filter the data
filter_func <- function(x, t, fc){
  ## x is the vector array that need to be filter
  ## t the time component of the vector array
  ## cf is the cut off frequency
  
  ## fs (sampling frequency)= no of samples/ sampling time (max time)
  fs <- length(x)/max(t)   # sampling frequency
  ns <- length(x)  # number of samples
  s <- ts(x, frequency = fs) ## convert sample to ts object with sampling rate as fs
  ft <- fft(s) ## fourier transform
  lft <- length(ft) ## length of fourier transform
  bin <- ns/(fs/fc) ## Create the upper bin cut-off point
  ft[-c(1:bin, (lft-bin):lft)] <- 0 ## Null the upper bins
  
  x_lowpass.f <- Re(fft(ft, inv=TRUE))/lft ## lowe pass filter
  return(x_lowpass.f)
}


##### Plot some of the data
### NIB446 == HV, difficulty hands direction: LH, LH, LH
### NIB632 == MS, difficulty hands direction: RH, LH, RH
### NDS670 == Others, difficulty hands direction: LH, LH, LH

p1 <- subset(ms_data4, patient_id=="NDS670") ## select single patient ## NIB112 ##NDS668, NDS670
p1$difficulty_level <- factor(p1$difficulty_level, 
                              labels = c("Difficulty Level 1","Difficulty Level 2",
                                                              "Difficulty Level 3"))
p11 <- subset(p1, ntest_date=="1") ## select one test date (1)
p111 <- subset(p11, difficulty_level=="Difficulty Level 3") ## select single difficulty level (1)
p1111 <- subset(p111, trial_id == p111$trial_id[1]) ## select one trial_id

## select only one trial_id
p11_sub <- p11 %>% 
  group_by(difficulty_level) %>% 
  dplyr::filter(trial_id==levels(factor(trial_id))[1])

### raw drawing
ggplot()+
  geom_point(data = spiral_LH, aes(x=x, y= y), size  = 2, color = "orange")+ ## app spiral
  geom_path(data = spiral_LH, aes(x=x, y= y), size = .9, color = "orange") +
  geom_point(data = p11_sub, aes(x=x, y= y), size  = 2)+ ## cohort spiral
  geom_path(data = p11_sub, aes(x=x, y= y), size = .9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "X-Coordinates", y = "Y-Coordinates") + 
  theme_bw() + Nice.Label

### velocity vs. time
ggplot(p11_sub, aes(x=time, y= filter_func(v_i,time,8)))+
  geom_point(size  = 2.0)+
  geom_line(size = 0.9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "Time (s)", y = "Drawing Velocity (Pixels/s)") + 
  theme_bw()+Nice.Label 


```






```{r  message=FALSE, warning=FALSE, include=FALSE}
## calculate the sum, coefiicient of variation, skew for v, rv, and av
## Function to calculate coefficient of variation
cv = function(vector){
  coefvar <- sd(vector, na.rm = TRUE)/ mean(vector, na.rm = TRUE)
  return(coefvar)
}

ms_data.av <- ms_data3 %>% 
  group_by(patient_id,ntest_date,difficulty_level) %>% 
  summarise(v_sum = sum(v_i), v_cv = cv(v_i), v_sk = skewness(v_i), 
            v_kt = kurtosis(v_i), 
            rv_sum = sum(rv_i), rv_cv = cv(rv_i), rv_sk = skewness(rv_i),
            rv_kt = kurtosis(rv_i),
            av_sum = sum(av_i), av_cv = cv(av_i), av_sk = skewness(av_i), 
            av_kt = kurtosis(av_i))


#### Power Spectral Density using Welsh periodogram with a Hamming window
## Maximum PSD and dominant i.e., frequency corresponding to max(PSD)--see Creagh et. al, 2020

## function to calculate PSD with hamming window of length = length(velocity vector)
pwelch_func <- function(vector){
  result = pwelch(vector, window = hamming(length(vector)), plot = FALSE)
  freq = result$freq
  spec = result$spec
  return(as.data.frame(list(freq=freq,spec=spec)))
}
  
  
ms_data.psd <- ms_data3 %>% 
   group_by(patient_id,ntest_date,difficulty_level) %>%
  summarise(v_psd.max = max(pwelch_func(v_i)$spec), 
            v_df = pwelch_func(v_i)$freq[which.max(pwelch_func(v_i)$spec)],
            rv_psd.max = max(pwelch_func(rv_i)$spec),
            rv_df = pwelch_func(rv_i)$freq[which.max(pwelch_func(rv_i)$spec)],
            av_psd.max = max(pwelch_func(av_i)$spec),
            av_df = pwelch_func(av_i)$freq[which.max(pwelch_func(av_i)$spec)])

### Power vs. frequency plot
## Create the data frame by filtering and calculating the power

p11_sub1 <- subset(p11_sub, difficulty_level == "Difficulty Level 1")
p11_sub2 <- subset(p11_sub, difficulty_level == "Difficulty Level 2")
p11_sub3 <- subset(p11_sub, difficulty_level == "Difficulty Level 3")

psd_df1 <- data.frame(difficulty_level = "Difficulty Level 1",
                      pwelch_func(filter_func(p11_sub1$v_i, p11_sub1$time, 8)))
psd_df2 <- data.frame(difficulty_level = "Difficulty Level 2",
                      pwelch_func(filter_func(p11_sub2$v_i, p11_sub2$time, 8)))
psd_df3 <- data.frame(difficulty_level = "Difficulty Level 3",
                      pwelch_func(filter_func(p11_sub3$v_i, p11_sub3$time, 8)))

psd_df <- rbind(psd_df1,psd_df2,psd_df3) ## row bind psd for all difficulty levels

ggplot(psd_df, aes(x =freq,spec))+
  geom_point(size  = 2.0)+
  geom_line(size = 0.9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "Frequency (Hz)", y = expression("Power (Pixels/s) "^2)) + 
  theme_bw()+Nice.Label 


### Approximate Entropy (ApEn)
## Interpolate all v_i, r_vi, av_i over a fixed length L = 500 (see similar approach in Creagh et al., 2020) and calculate their entropy 
ms_data.apen <- ms_data3 %>% 
   group_by(patient_id,ntest_date,difficulty_level) %>%
  summarise(v_apen = ApEn(spline(v_i, n = 500)$y), 
            rv_apen = ApEn(spline(rv_i, n = 500)$y), 
            av_apen = ApEn(spline(av_i, n = 500)$y))


p1.apen <- subset(ms_data.apen, patient_id=="rep029")
p1.apen <- p1.apen %>% select(patient_id, difficulty_level, v_apen)
  

ggplot(df2, aes(x=difficulty_level, y=v_apen)) + 
    geom_line(size  = 0.9) +
    geom_point(size  = 2.0)+
  labs(x = "Difficulty Levels", y = "Approximate Entory of v") +
    geom_errorbar(aes(ymin=v_apen-sd, ymax=v_apen+sd), width=.2, size = 0.9,
                  position=position_dodge(0.05))+ theme_bw() + Nice.Label


###


### "NIB657"    "NIB659"    "NIB661"    "NIB662"    "NIB663"    "NIB664"    "PATIENT10" 
##"NDS688"    "NDS689"    "NDS690"    "NDS691"    "NDS692"    "NDS693"    "NDS694"    "NDS696"
p1 <- subset(ms_data4, patient_id=="NIB446") ## select single patient ## NIB112 ##NDS668
p11 <- subset(p1, ntest_date=="1") ## select one test date (1)
p111 <- subset(p11, difficulty_level=="1") ## select single difficulty level (1)
p1111 <- subset(p111, trial_id == p111$trial_id[1]) ## select one trial_id
##

t <- p1111$time
x <- p1111$v_i
z <- filter_func(x, t, 8) # apply filter
## fs (sampling frequency)= no of samples/ sampling time (max time)
## The highest frequency  is assumed to be fs/2

pz <- pwelch_func(z) 

plot(pz$freq,pz$spec, 'o')

plot(t,x,'o')
lines(t,z,col="orange")

```








