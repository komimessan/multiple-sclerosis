# Introduction

Smartphone devices may be an easier alternative to obtain data from patients outside of clinics and hospitals environment. In this project, smartphone-based data were obtained from Multiple Sclerosis (MS) patients using a drawing a spiral test. The test was administered in order to measure upper extremity functionality. 

```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
### Libraries
library(openxlsx) ## v. 4.1.5
library(dplyr) ## v. 1.0.0
library(ggplot2) ## v. 3.3.1
library(wavelets) ## v. 0.3.0.2 ## for wavelet transform -- https://cran.r-project.org/web/packages/wavelets/wavelets.pdf
library(signal) ## v. 0.7.6 ## for filtering -- https://cran.r-project.org/web/packages/signal/signal.pdf
library(e1071) ## v. 1.7.3
library(psd) ## v. 2.1.0 ## power spectral density -- https://cran.r-project.org/web/packages/psd/psd.pdf
library(TSEntropies) ## v. 0.9 ## to calculate Approximate Entropies (ApEn)-- https://cran.r-project.org/web/packages/TSEntropies/TSEntropies.pdf
library(oce) ## v.1.2.0 ## oceanographic library which contain PSD with hamming window
library(tidyr) ## v. 1.1.0 ## for gather and wide
library(VennDiagram) ## v. ## Venn diagram 
```




```{r  message=FALSE, warning=FALSE, include=FALSE}
### Import data
## Description of the data is as follow
# Patient = Subject ID
# x: distance (in inches) of the spot drawn from the center of the screen
# y: distance (in inches) of the spot drawn from the center of the screen
# p: estimated pressure of the tap (based off of surface area)
# t: UNIX timestamp of when the drawing happened (to the millisecond)
# sumData.Num turns: the number of turns in the spiral 
# sumData.Line width: the width of the lines of the spiral
# time.point: UNIX timestamp of the drawing (this time in seconds)



ms_data <- read.csv("spiralDataCorrected.csv", header = TRUE) ## multiple sclerosis
cl_data <- read.csv("Clinical_Data.csv", header = TRUE) ## clinical


#### Clean up the MS data
## add a test date to the data 
ms_data$testdate <- substr(ms_data$testDate,1,10)

## Remove non-relevant rows that have patient ID such as x:1234455
ms_data <- ms_data[substr(ms_data$patientID,1,2) != "x:" & 
                     substr(ms_data$patientID,1,2) != "{t" & 
                     substr(ms_data$patientID,1,2) != "y:" &
                     substr(ms_data$patientID,1,2) != "z:" &
                     substr(ms_data$patientID,1,2) != "t:" &
                     substr(ms_data$patientID,1,2) != "" &
                     substr(ms_data$patientID,1,11) != "UPLOAD_DATE" &
                     substr(ms_data$patientID,1,9) != "Altitude:",]

## and convert variable to numeric
ms_data$x <- as.numeric(as.character(ms_data$x))
ms_data$y <- as.numeric(as.character(ms_data$y))
ms_data$t <- as.numeric(as.character(ms_data$t))
ms_data$p <- as.numeric(as.character(ms_data$p))
ms_data$age <- as.numeric(as.character(ms_data$age))
ms_data$testdate <- as.Date(ms_data$testdate, format = "%Y-%m-%d")

### Certain patients are incorrect so they are changed
### NIB380 on 5/22/19 – change the patient code to NIB370 
### NIB649 on 3/14/19 – change the patient code to NIB640 
### NIB685 on 12/12/18 – change the patient code to NDS685 
### NIB703 on 8/21/19 – change the patient code to NDS703 

ms_data[ms_data$patientID =="NIB380" & ms_data$testdate=="2019-05-22",]$patientID <- "NIB370"
ms_data[ms_data$patientID =="NIB649" & ms_data$testdate=="2019-03-14",]$patientID <- "NIB640"
ms_data[ms_data$patientID =="NIB685" & ms_data$testdate=="2018-12-12",]$patientID <- "NDS685"
ms_data[ms_data$patientID =="NIB703" & ms_data$testdate=="2019-08-21",]$patientID <- "NDS703"

## Retrive some of the healthy volunteers that start with PATIENT..
HV_Patient <- ms_data[substr(ms_data$patientID,1,7)=="PATIENT",]

## add visit number based on patientID and difficulty level, remove some columns and change column names
ms_data2 <- ms_data %>% 
  group_by(patientID, difficulty) %>%
  mutate(ntest_date = factor(testdate, labels = 1:length(unique(testdate)))) %>% 
  dplyr::select(trialID, patientID,x,y,t,p,ntest_date,difficulty, testdate, appendage) %>% 
  dplyr::rename(trial_id = trialID, patient_id=patientID,difficulty_level=difficulty)

ms_data2$t <- ms_data2$t/1000 ## convert time point from milliseconds to seconds 

## add time that is scaled from 0 by patient_id, ntest_date, and difficulty_level and remove duplicate x, y, t
ms_data2 <- ms_data2 %>% 
  group_by(patient_id, ntest_date, difficulty_level, trial_id) %>% 
  distinct(x,y,t,p, .keep_all = TRUE) %>% 
  arrange(t) %>% 
  mutate(pixel = row_number(), time = t-t[1])


####### Clinical data
#### Add new diagnosis category to the clinical data 
#### (MS, HV, and Others for all others disorder)
cl_data$diagnosis_group <- ifelse(
  cl_data$diagnosis=="PP-MS" | cl_data$diagnosis=="RR-MS" | cl_data$diagnosis=="SP-MS","MS",
                                   ifelse(cl_data$diagnosis=="Healthy Donor","HV", "Others"))

## round age to the nearest integer
cl_data$age <- round(cl_data$age)

## Create clinical data that contain patient that intersect with those in the ms_data
cl_data.sub <- cl_data %>% 
  #dplyr::filter(NeurExPatientID %in% ms_data2$patient_id) %>% 
  dplyr::rename(dominant_hand = handedness, patient_id=NeurExPatientID, 
                testdate = "AppTestDate", neuro_testdate ="NeurExDate",
                apptest_to_neurotest = "X..days.between.app.test.and.clinic.visit") 

## Change the format of the test dates and check difference between test dates (app and neuro)
cl_data.sub$testdate <- as.Date(cl_data.sub$testdate, format = "%m/%d/%Y")
cl_data.sub$neuro_testdate <- as.Date(cl_data.sub$neuro_testdate, format = "%m/%d/%Y")

## patient and testdates in both datasets
patient_ms_cl <- intersect(ms_data2$patient_id,cl_data.sub$patient_id) 
testdate_ms_cl <- intersect(ms_data2$testdate,cl_data.sub$testdate) 

## Clinical datasets with patient IDs and testdates in MS datasets
cl_data.sub2 <- cl_data.sub %>% 
  dplyr::filter(patient_id %in% patient_ms_cl & testdate %in% testdate_ms_cl) 

## MS datasets with patient IDs and testdates in clinicla datasets
ms_data2 <- ms_data2 %>% semi_join(cl_data.sub2, by = c("patient_id","testdate"))

#### Join the cl_data.sub to the ms_data2 
ms_data3 <- merge(ms_data2, cl_data.sub2, by = c("patient_id", "testdate"), all = TRUE)

## Arrange ms_data3 by patient_id,ntest_date, difficulty_level, trial_id, and time
ms_data3 <- arrange(ms_data3,patient_id,ntest_date, difficulty_level, trial_id, time)

```




```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width= 16}
#### create template for plot labelling
black.bold.text1 <- element_text(face = "bold", color = "black",size=24) # x and y axis
black.bold.text2 <- element_text(face = "bold", color = "black",size=24) # title
Nice.Label <-theme(axis.text.x = element_text(face="bold", color="black", size=16),
         axis.text.y = element_text(face="bold", color="black", size=16),
         title=black.bold.text2,axis.title = black.bold.text1, legend.position = "right",legend.box = "vertical",
         legend.text = element_text(size=24),strip.text.x = element_text(face="bold",size=24)) #18 or 24

### Tranform from long tabel to wide table

metadata_sub.long <- ms_data3 %>% 
  dplyr::distinct(patient_id, .keep_all = TRUE) %>%
  dplyr::select(patient_id,diagnosis_group,dominant_hand, gender) %>%
  tidyr::gather(group, attribute, diagnosis_group:gender, factor_key = TRUE) 

metadata_sub.long$group <- factor(metadata_sub.long$group,
                                  levels = c("diagnosis_group","gender","dominant_hand"),
                                  labels = c("Diagnosis Categories", "Gender", "Dominant Hand"))

### Plot the distribution of the type of data we have 
ggplot(metadata_sub.long, aes(x=attribute)) +
  geom_bar(colour = "gray", width = 0.5) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.2, size = 6) +
  facet_wrap(~group, scales = "free", nrow = 1) +
  labs(x = " ", y = "Number of Cohorts") +
  theme_bw()+Nice.Label

```



# Features extraction

As previously done in [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf), several features can extracted from drawing shape by an MS patient to capture temporal, spatial,and spatiotemporal factors in the drawing task that could be an indicative of manual dexterity. Thus we start by calculating each of these features:

## Temporal features

To measure temporal irregularities, several authors ( [Banaszkiewicz et al., 2008](https://europepmc.org/article/med/19353440), [Memedi et al., 2015](https://www.mdpi.com/1424-8220/15/9/23727), [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf) ) calculated the drawing velocities,angular and radial velocities to illustrate temporal features that may emerge in the upper extremity function of MS patients. These features were calculated using the following formula from ( [Memedi et al., 2015](https://www.mdpi.com/1424-8220/15/9/23727) and [Creagh et al., 2020](https://iopscience.iop.org/article/10.1088/1361-6579/ab8771/pdf) ):


$$v = \sum_{i=1}^{N-1} \frac{\sqrt{(x_{i+1}-x_i)^2 + (y_{i+1}-y_i)^2}}{t_{i+1}-t_i}$$
with $v$ the drawing velocity. Radial velocity (RV) is calculated as:
$$RV = \sum_{i=1}^{N-1} \frac{r_{i+1}-r_i}{t_{i+1}-t_i}$$
where $r = \sqrt{x^2+y^2}$ is the radius. Angular velocity (RHOV) is also calculated as 

$$RHOV = \sum_{i=1}^{N-1} \frac{\theta_{i+1}-\theta_i}{t_{i+1}-t_i}$$

where $\theta = tan^{-1}\left(\frac{y}{x}\right)$. $x$ and $y$ in each formula are the coordinates of the drawing pixel and $t$ is time in seconds. $N$ is the total number of pixel.




```{r  message=FALSE, warning=FALSE, include=FALSE}

# ## Calculate velocity (v), radial velocity (rv), angular velocity (av) by patients, test date, and difficulty level
# ## Initialize velocity (v), radial velocity (rv), angular velocity (rhov)
# ms_data3[,"d_t"] <- 0 ## intialize an empty 0 column of delta time
# ms_data3[,"v_i"] <- 0 ## intialize an empty 0 column of velocities
# ms_data3[,"rv_i"] <- 0 ## intialize an empty 0 column of radial velocities
# ms_data3[,"av_i"] <- 0 ## intialize an empty 0 column of angular velocities
# 
# # create an empty dataframe to be used later
# new.tr.level <- ms_data3[0,]
# 
# ## factor levels of patient ID
# p.id <- levels(factor(ms_data3$patient_id))
# 
# ptm <- proc.time() ## Check how long it will run (will take 11 min to run)
# 
# for (id in p.id) {
#   patient_data <- subset(ms_data3, patient_id==id) ## select a single patient
#   n.test <- levels(factor(patient_data$ntest_date))
#   for (tn in n.test) {
#     test_date <- subset(patient_data, ntest_date==tn) ## select one test date
#     d.levels <- levels(factor(test_date$difficulty_level))
#     for (dl in d.levels) {
#       d.level <- subset(test_date, difficulty_level==dl) ## select difficulty level
#       tr.levels <- levels(factor(d.level$trial_id))
#       for (tr in tr.levels){
#         tr.level <- subset(d.level, trial_id==tr) ## select trial_id
#         dim_tr.level1 <- dim(tr.level)[1] ## Make sure the dimension of each trial > 2
#         if (dim_tr.level1>2){
#           for (i in 1:(dim_tr.level1 - 1)) {
#             tr.level[i+1,"d_t"] <- (tr.level$time[i+1]-tr.level$time[i]) # delta time
#             tr.level[i+1,"v_i"] <- sqrt((tr.level$x[i+1] - tr.level$x[i])^2 +
#                                           (tr.level$y[i+1] - tr.level$y[i])^2
#             )/(tr.level$time[i+1]-tr.level$time[i]) # velocity
#             tr.level[i+1,"rv_i"] <- (sqrt((tr.level$x[i+1])^2 + (tr.level$y[i+1])^2) -                                       sqrt((tr.level$x[i])^2 + (tr.level$y[i])^2)
#             )/(tr.level$time[i+1]-tr.level$time[i]) # radial velocity
#             tr.level[i+1,"av_i"] <- (atan(tr.level$y[i+1]/tr.level$x[i+1]) -
#                                        atan(tr.level$y[i]/tr.level$x[i])
#             )/(tr.level$time[i+1]-tr.level$time[i]) # angular velocity
# 
#           }
#           new.tr.level <- rbind(new.tr.level, tr.level) ## append the data
#         }
#       }
#     }
#   }
# }
# proc.time() - ptm
# 
# # ## call the final data, ms_data4
# ms_data4 <- new.tr.level

## The code to calculate v, rv, and av take long so the data was saved to be used later
ms_data4 <- read.csv("new_spiralLH.csv", header = TRUE)


# ## Write the ms_data4 containing vi, rvi, and avi to the file to be used later
# #write.csv(ms_data4,file = "new_spiralLH.csv")
# 
# # #### Tryout for a single patient
# # 
# ms_data3p <- subset(ms_data3, v_i>0)

# ## 
# p1 <- subset(ms_data3, patient_id=="NIB112") ## select single patient ##NDS668, NDS670
# p11 <- subset(p1, ntest_date=="1") ## select one test date 
# p111 <- subset(p11, difficulty_level=="1") ## select single difficulty level 
# p1111 <- subset(p111, trial_id == p111$trial_id[1]) ## select one trial_id
#
# ### filter the speed fequency by 8 Hz
# bf <- butter(3, 0.08) # 8 Hz low-pass filter
# t <- p111$t - p111$t[1]
# x <- p111$v_i
# z <- filter(bf, x) # apply filter
# plot(t, x, type = "l")
# lines(t, z, col = "red")
#
# # #
# d.t = rep(0, dim(p1111)[1]) ## initialize delta time
# p1111_v = rep(0, dim(p1111)[1]) ## initialize the velocity of p111
# p1111_rv = rep(0, dim(p1111)[1]) ## initialize the radial velocity
# p1111_av = rep(0, dim(p1111)[1]) ## initialize the angular velocity
# #
# for (i in 1:(dim(p1111)[1]-1)){
#   d.t[i+1] = (p1111$time[i+1]-p1111$time[i])
#   p1111_v[i+1] <- sqrt((p1111$x[i+1] - p1111$x[i])^2 + (p1111$y[i+1] - p1111$y[i])^2)/(p1111$time[i+1]-p1111$time[i])
#   p1111_rv[i+1] <-  (sqrt((p1111$x[i+1])^2 + (p1111$y[i+1])^2) - sqrt((p1111$x[i])^2 + (p1111$y[i])^2))/(p1111$time[i+1]-p1111$time[i])
#   p1111_av[i+1] <-  (atan(p1111$y[i+1]/p1111$x[i+1]) - atan(p1111$y[i]/p1111$x[i]))/(p1111$time[i+1]-p1111$time[i])
# }
# # # 
# # p111_rv.dwt <- dwt(p111_rv, filter = "d10")
# # cp111_rv.dwt <- p111_rv.dwt@filter@h ## Coefficient
```





```{r  message=FALSE, warning=FALSE, include=FALSE}

#### Recreate the original spiral drawing from the App

## Turn Difficulty level into Number of Turns
DifficultyToNumberOfTurns <- function(difficulty){
  if(difficulty=="3"){
    return(5)
  } else if (difficulty == "2"){
    return(3)
  } else {
    return(2)
  }
}

## Turn difficulty level into the Line width
DifficultyToLineWidth <- function(difficulty){
  if(difficulty=="1"){
    return(6/32)
  } else if (difficulty == "2"){
    return(5/32)
  } else {
    return(4/32)
  }
}


## Function to generate the spiral data
GenerateSpiral = function(side, difficulty){
  ## side can either be LH or RH from the appendage in ms_data
  ## difficulty is the dificulty level from 1,2 or 3
  
  NumberOfTurns <- DifficultyToNumberOfTurns(difficulty)
  MaxAngleRadians <- 2*pi*NumberOfTurns
  MaxRadius <- 1.25
  AngleToRadiusScale <- MaxRadius/MaxAngleRadians
  AngleOffset <- pi/2
  InvertFactor <- ifelse(side=="LH",1,-1)
  
  CurAngleRadian <- 0
  x_vec <- vector() ## Initialize the x vector
  y_vec <- vector() ## initialize the y vector
  
  while (CurAngleRadian < MaxAngleRadians) {
    x <- CurAngleRadian*AngleToRadiusScale*cos((CurAngleRadian * InvertFactor) + AngleOffset)
    y <- CurAngleRadian*AngleToRadiusScale*sin((CurAngleRadian * InvertFactor) + AngleOffset)
    
    x_vec <- append(x_vec,x)
    y_vec <- append(y_vec,y)
    CurAngleRadian = CurAngleRadian + 0.1
  }
  
  linewidth <- rep(DifficultyToLineWidth(difficulty), length(x_vec))
  
  return(list(x=x_vec, y=y_vec, linewidth = linewidth))
}

## generate spiral with difficulty 1, 2, and 3
spiral_dl1.LH <- as.data.frame(GenerateSpiral("RH",1))
spiral_dl1.LH$difficulty_level = rep("Difficulty Level 1", dim(spiral_dl1.LH)[1])
spiral_dl2.LH <- as.data.frame(GenerateSpiral("LH",2))
spiral_dl2.LH$difficulty_level = rep("Difficulty Level 2", dim(spiral_dl2.LH)[1])
spiral_dl3.LH <- as.data.frame(GenerateSpiral("RH",3))
spiral_dl3.LH$difficulty_level = rep("Difficulty Level 3", dim(spiral_dl3.LH)[1])

spiral_LH <- rbind(spiral_dl1.LH, spiral_dl2.LH, spiral_dl3.LH)
linewidth <- spiral_LH$linewidth
```




```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width= 16}

## Create a function that will use Fourier Transform to lowpass filter the data
filter_func <- function(x, t, fc){
  ## x is the vector array that need to be filter
  ## t the time component of the vector array
  ## cf is the cut off frequency
  
  ## fs (sampling frequency)= no of samples/ sampling time (max time)
  fs <- length(x)/max(t)   # sampling frequency
  ns <- length(x)  # number of samples
  ## convert sample to ts object with sampling rate as fs
  s <- na.omit(ts(x, frequency = fs)) 
  ft <- fft(s) ## fourier transform
  lft <- length(ft) ## length of fourier transform
  bin <- ns/(fs/fc) ## Create the upper bin cut-off point
  
  if (lft>=bin){
    ft[-c(1:bin, (lft-bin):lft)] <- 0 ## Null the upper bins
  } else{
    ft <- ft ## No filter if lft is larger than bin
  }
  x_lowpass.f <- Re(fft(ft, inv=TRUE))/lft ## lowe pass filter
  return(x_lowpass.f)
}


##### Plot some of the data
### NIB446 == HV, difficulty hands direction: LH, LH, LH
### NIB632 == MS, difficulty hands direction: RH, LH, RH
### NDS670 == Others, difficulty hands direction: LH, LH, LH

p1 <- subset(ms_data4, patient_id=="NIB657") ## select single patient ## NIB112 
p1$difficulty_level <- factor(p1$difficulty_level, 
                              labels = c("Difficulty Level 1","Difficulty Level 2",
                                                              "Difficulty Level 3"))
p11 <- subset(p1, ntest_date=="1") ## select one test date (1)
p111 <- subset(p11, difficulty_level=="Difficulty Level 2") ## select single difficulty level (1)
p1111 <- subset(p111, trial_id == p111$trial_id[1]) ## select one trial_id

## select only one trial_id
p11_sub <- p11 %>% 
  group_by(difficulty_level) %>% 
  dplyr::filter(trial_id==levels(factor(trial_id))[1])


spiral_data_func <- function(data, patientID, ntest){
  ## data is the dataframe
  ## patientID is the patient Id
  ## ntest is the nth number of testdate for patient i
  
  p1 <- subset(data, patient_id == patientID)
  p1$difficulty_level <- factor(p1$difficulty_level, 
                                labels = c("Difficulty Level 1","Difficulty Level 2",
                                           "Difficulty Level 3"))
  p11 <- subset(p1, ntest_date==ntest) ## select one test date (1)
  p11_sub <- p11 %>% 
    group_by(difficulty_level) %>% 
    dplyr::filter(trial_id==levels(factor(trial_id))[1]) %>% 
    dplyr::select(patient_id, testdate, difficulty_level, trial_id, 
                  ntest_date,time, x, y, v_i, rv_i, av_i, appendage)

  ## generate spiral with difficulty 1, 2, and 3
  dl1 <- "Difficulty Level 1"
  dl2 <- "Difficulty Level 2"
  dl3 <- "Difficulty Level 3"
  append1 <- subset(p11_sub,difficulty_level == dl1)$appendage[1]
  append2 <- subset(p11_sub,difficulty_level == dl2)$appendage[1]
  append3 <- subset(p11_sub,difficulty_level == dl3)$appendage[1]
  
  spiral_dl1 <- as.data.frame(GenerateSpiral(append1,1))
  spiral_dl1$difficulty_level = rep(dl1, dim(spiral_dl1.LH)[1])
  spiral_dl2 <- as.data.frame(GenerateSpiral(append2,2))
  spiral_dl2$difficulty_level = rep(dl2, dim(spiral_dl2.LH)[1])
  spiral_dl3 <- as.data.frame(GenerateSpiral(append3,3))
  spiral_dl3$difficulty_level = rep(dl3, dim(spiral_dl3.LH)[1])
  
  spiral_data <- rbind(spiral_dl1, spiral_dl2, spiral_dl3)
  colnames(spiral_data) <- c("xt","yt","linewidth","difficulty_level")
  
  ## Create the new normnalized x and y coordinates by assuming 
  ## every first point is correct
  
  ## normalization factor
  norm.x1 <- last(spiral_dl1$x) - subset(p11_sub,difficulty_level == dl1)$x[1]
  norm.y1 <- last(spiral_dl1$y) - subset(p11_sub,difficulty_level == dl1)$y[1]
  norm.x2 <- last(spiral_dl2$x) - subset(p11_sub,difficulty_level == dl2)$x[1]
  norm.y2 <- last(spiral_dl2$y) - subset(p11_sub,difficulty_level == dl2)$y[1]
  norm.x3 <- last(spiral_dl3$x) - subset(p11_sub,difficulty_level == dl3)$x[1]
  norm.y3 <- last(spiral_dl3$y) - subset(p11_sub,difficulty_level == dl3)$y[1]
  
  ## add x_norm and y_norm
  p11_sub$x_norm <- ifelse(p11_sub$difficulty_level==dl1, p11_sub$x + norm.x1,
                           ifelse(p11_sub$difficulty_level==dl2, p11_sub$x + norm.x2,
                                  p11_sub$x + norm.x3))
  p11_sub$y_norm <- ifelse(p11_sub$difficulty_level==dl1, p11_sub$y + norm.y1,
                           ifelse(p11_sub$difficulty_level==dl2, p11_sub$y + norm.y2,
                                  p11_sub$y + norm.y3))
  
  
  return(list(patient_spiral = p11_sub, true_spiral = spiral_data))
  #spiral_dat <- merge(p11_sub,spiral_LH, by = "difficulty_level", all = TRUE)
}


## Compute the spiral according to the appendage and extract data for plotting
spiral_data <- spiral_data_func(ms_data4, "NIB657","1")
patient_spiral <- as.data.frame(spiral_data$patient_spiral)
true_spiral <- as.data.frame(spiral_data$true_spiral)
linewidth <- spiral_data$true_spiral$linewidth
### raw drawing
##  lwd=1 is equal to 1/96 inch, which is exactly as 0.75 * 1/72 inch (0.75pt)
ggplot()+
  #geom_point(data = spiral_LH, aes(x=x, y= y), size  = 2, color = "orange")+ ## app spiral
  geom_path(data = true_spiral, aes(x=xt, y= yt), lwd = (linewidth*96)/3, color = "orange") +
  geom_point(data = patient_spiral, aes(x=x_norm, y= y_norm), size  = 2)+ ## cohort spiral
  geom_path(data = patient_spiral, aes(x=x_norm, y= y_norm), size = .9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "X-Coordinates", y = "Y-Coordinates") + 
  theme_bw() + Nice.Label

## spiral normalized drawing

ggplot()+
  #geom_point(data = spiral_LH, aes(x=x, y= y), size  = 2, color = "orange")+ ## app spiral
  geom_path(data = true_spiral, aes(x=xt, y= yt), lwd = (linewidth*96)/3, color = "orange") +
  geom_point(data = patient_spiral, aes(x=x, y= y), size  = 2)+ ## cohort spiral
  geom_path(data = patient_spiral, aes(x=x, y= y), size = .9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "X-Coordinates", y = "Y-Coordinates") + 
  theme_bw() + Nice.Label

### velocity vs. time
ggplot(patient_spiral, aes(x=time, y= filter_func(v_i,time,8)))+
  geom_point(size  = 2.0)+
  geom_line(size = 0.9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "Time (s)", y = "Drawing Velocity (Pixels/s)") + 
  theme_bw()+Nice.Label 



p11_sub2 <- p11_sub %>% 
  group_by(difficulty_level) %>% 
  mutate(x = x - first(x), y= y-first(y))
```






```{r  message=FALSE, warning=FALSE, include=FALSE}
## calculate the sum, coefiicient of variation, skew for v, rv, and av
## Function to calculate coefficient of variation
cv = function(vector){
  coefvar <- sd(vector, na.rm = TRUE)/ mean(vector, na.rm = TRUE)
  return(coefvar)
}

ms_data.sum <- ms_data4 %>% 
  group_by(patient_id,ntest_date,difficulty_level, trial_id) %>% 
  summarise(v_sum = sum(v_i, na.rm = TRUE), v_cv = cv(v_i), 
            v_sk = skewness(v_i, na.rm = TRUE), v_kt = kurtosis(v_i, na.rm = TRUE), 
            rv_sum = sum(rv_i, na.rm = TRUE), rv_cv = cv(rv_i), 
            rv_sk = skewness(rv_i, na.rm = TRUE), na.rm = TRUE, rv_kt = kurtosis(rv_i),
            av_sum = sum(av_i,na.rm = TRUE), av_cv = cv(av_i), 
            av_sk = skewness(av_i, na.rm = TRUE), av_kt = kurtosis(av_i, na.rm = TRUE))


#### Power Spectral Density using Welsh periodogram with a Hamming window
## Maximum PSD and dominant i.e., frequency corresponding to max(PSD)--see Creagh et. al, 2020

## function to calculate PSD with hamming window of length = length(velocity vector)
pwelch_func <- function(vector){
  result = pwelch(vector, window = hamming(length(vector)), plot = FALSE)
  freq = result$freq
  spec = result$spec
  return(as.data.frame(list(freq=freq,spec=spec)))
}
  
  
ms_data.psd <- ms_data4 %>% 
   group_by(patient_id, ntest_date, difficulty_level, trial_id) %>%
  summarise(v_psd.max = max(pwelch_func(filter_func(v_i,time,7))$spec), 
            v_df = pwelch_func(filter_func(v_i,time,7))$freq[which.max(pwelch_func(filter_func(v_i,time,7))$spec)],
            rv_psd.max = max(pwelch_func(filter_func(rv_i,time,7))$spec),
            rv_df = pwelch_func(filter_func(rv_i,time,7))$freq[which.max(pwelch_func(filter_func(rv_i,time,7))$spec)],
            av_psd.max = max(pwelch_func(filter_func(av_i,time,7))$spec),
            av_df = pwelch_func(filter_func(av_i,time,7))$freq[which.max(pwelch_func(filter_func(av_i,time,7))$spec)])

### Power vs. frequency plot
## Create the data frame by filtering and calculating the power

p11_sub1 <- subset(p11_sub, difficulty_level == "Difficulty Level 1")
p11_sub2 <- subset(p11_sub, difficulty_level == "Difficulty Level 2")
p11_sub3 <- subset(p11_sub, difficulty_level == "Difficulty Level 3")

psd_df1 <- data.frame(difficulty_level = "Difficulty Level 1",
                      pwelch_func(filter_func(p11_sub1$v_i, p11_sub1$time, 8)))
psd_df2 <- data.frame(difficulty_level = "Difficulty Level 2",
                      pwelch_func(filter_func(p11_sub2$v_i, p11_sub2$time, 8)))
psd_df3 <- data.frame(difficulty_level = "Difficulty Level 3",
                      pwelch_func(filter_func(p11_sub3$v_i, p11_sub3$time, 8)))

psd_df <- rbind(psd_df1,psd_df2,psd_df3) ## row bind psd for all difficulty levels

ggplot(psd_df, aes(x =freq,spec))+
  geom_point(size  = 2.0)+
  geom_line(size = 0.9) +
  facet_wrap(~difficulty_level, scales = "free", nrow = 3) +
  labs(x = "Frequency (Hz)", y = expression("Power (Pixels/s) "^2)) + 
  theme_bw()+Nice.Label 


### Approximate Entropy (ApEn)
## Interpolate all v_i, r_vi, av_i over a fixed length L = 500 (see similar approach in Creagh et al., 2020) and calculate their entropy 
ms_data.apen <- ms_data4 %>% 
   group_by(patient_id,ntest_date,difficulty_level, trial_id) %>%
  summarise(v_apen = ApEn(spline(v_i, n = 500)$y), 
            rv_apen = ApEn(spline(rv_i, n = 500)$y), 
            av_apen = ApEn(spline(av_i, n = 500)$y))


p1.apen <- subset(ms_data.apen, patient_id=="NIB632" & ntest_date=="1")
p1.apen <- p1.apen %>% select(patient_id, difficulty_level, v_apen)
p1.apen$difficulty_level <- as.factor(p1.apen$difficulty_level)
  
#+++++++++++++++++++++++++
# Function to calculate the mean and the standard deviation
  # for each group
#+++++++++++++++++++++++++
# data : a data frame
# varname : the name of a column containing the variable
  #to be summariezed
# groupnames : vector of column names to be used as
  # grouping variables
data_summary <- function(data, varname, groupnames){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      sd = sd(x[[col]], na.rm=TRUE))
  }
  data_sum<-ddply(data, groupnames, .fun=summary_func,
                  varname)
  data_sum <- rename(data_sum, c("mean" = varname))
 return(data_sum)
}

####

p1.apen.sum <- data_summary(p1.apen, "v_apen", "difficulty_level")
  
ggplot(p1.apen.sum, aes(x=difficulty_level, y=v_apen)) + 
    geom_bar(stat="identity", color="black", colour = "gray", width = 0.5, 
           position=position_dodge()) +
  labs(x = "Difficulty Levels", y = "Approximate Speed Entropy") +
    geom_errorbar(aes(ymin=v_apen-sd, ymax=v_apen+sd), width=.2, size = 0.9,
                  position=position_dodge(0.05))+ theme_bw() + Nice.Label


###


### "NIB657"    "NIB659"    "NIB661"    "NIB662"    "NIB663"    "NIB664"    "PATIENT10" 
##"NDS688"    "NDS689"    "NDS690"    "NDS691"    "NDS692"    "NDS693"    "NDS694"    "NDS696"
p1 <- subset(ms_data4, patient_id=="NIB205") ## select single patient ## NIB112 ##NDS668
p11 <- subset(p1, ntest_date=="36") ## select one test date (1)
p111 <- subset(p11, difficulty_level=="2") ## select single difficulty level (1)
p1111 <- subset(p111, trial_id == "inZJofKGHweVTKUO28es") ## "JSpymPxwdnXwvLzXpjym"
##

x<- p1111$x - p1111$x[25]
y<- p1111$y - p1111$y[25]

t <- p1111$time
x <- p1111$av_i
z <- filter_func(x, t, 8) # apply filter
## fs (sampling frequency)= no of samples/ sampling time (max time)
## The highest frequency  is assumed to be fs/2

pz <- pwelch_func(z) 

plot(pz$freq,pz$spec, 'o')

plot(t,x,'o')
lines(t,z,col="orange")

```




```{r  echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width= 10}

library(VennDiagram)

spiraldata1 <- read.csv("spiralDS1.csv", header = TRUE)

Spiral_Vanessa <- ms_data$patientID
Spiral_Peter <- spiraldata1$metaData.ID

S_vanessa.l <- length(levels(factor(Spiral_Vanessa)))
S_Peter.l <- length(levels(factor(Spiral_Peter)))
cross.area <- length(intersect(Spiral_Vanessa,Spiral_Peter))
diff_Van.Pet <- setdiff(Spiral_Vanessa,Spiral_Peter)
diff_Pet.Van <- setdiff(Spiral_Peter,Spiral_Vanessa)

grid.newpage();
venn.plot <- draw.pairwise.venn(area1 = S_vanessa.l, 
                                area2 = S_Peter.l, 
                                cross.area = cross.area,
                                #col = "red",
                                lty = "blank",
                                cat.cex = c(1.5,1.5), cex = c(2.5,2.5,2.5),
                 fill = c("green", "blue"),
                 category = c("Vanessa Data", "Peter Data"));
grid.draw(venn.plot)


### Splitting the dataset
#a # original data frame

#train<-sample_frac(a, 0.7)
#sid<-as.numeric(rownames(train)) # because rownames() returns character
#test<-a[-sid,]

## euclidean distance
euc.dist <- function(x2,y2){
  x1 <- 0
  y1 <- 0
  return(sqrt((x1 - x2) ^ 2 + (y1-y2)^2))
}

ms_dist <- tibble::as_tibble(ms_data4) %>% 
  group_by(patient_id, ntest_date, difficulty_level, trial_id) %>% 
  summarise(dist = euc.dist(x,y)) %>% 
  slice(1)

ms_dist$difficulty_level <- factor(ms_dist$difficulty_level, 
                                   labels = c("Difficulty Level 1",
                                              "Difficulty Level 2",
                                              "Difficulty Level 3") )


ggplot(ms_dist, aes(x=dist)) +
  geom_histogram(color="darkblue", fill="lightblue", bins = 50) +
  facet_wrap(~difficulty_level, nrow = 1, scales = "free") +
  labs(x = "Euclidean Distance between (0,0) and First Spiral Point", y = "Count") +
  theme_bw() + Nice.Label

ms_dist.var <- tibble::as_tibble(ms_dist)  %>% 
  group_by(patient_id, difficulty_level) %>% 
  summarise(dist_var = var(dist))

ggplot(ms_dist.var, aes(x=dist_var)) +
  geom_histogram(color="darkblue", fill="lightblue", bins = 10) +
  facet_wrap(~difficulty_level, nrow = 1, scales = "free") +
  labs(x = "Variance of Euclidean Distance by Patient", y = "Count") +
  theme_bw() + Nice.Label

```








